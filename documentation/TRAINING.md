# Training the VishwamAI Chat Agent Model

## Environment Setup
To set up the training environment, follow these steps:

1. **Install Required Software**:
   - Python 3.8 or higher
   - JAX
   - Haiku
   - PyTorch
   - Hugging Face Transformers
   - Tesseract OCR
   - PyMuPDF
   - pydub
   - SpeechRecognition

2. **Install Dependencies**:
   - Navigate to the project directory and run:
     ```bash
     pip install -r requirements.txt
     ```

3. **Hardware Requirements**:
   - A machine with a GPU is recommended for faster training.
   - Ensure you have sufficient disk space for storing datasets and model checkpoints.

## Training Data
The training and evaluation datasets should be placed in the `data/processed/` directory. The expected file paths are:

- `data/processed/train.txt`
- `data/processed/eval.txt`

### Dataset Format
The datasets should be in plain text format, with each line representing a training example.

### Obtaining Datasets
If you do not have the datasets, please contact the project maintainer or refer to the project's data acquisition guidelines.

## Running the Training Script
To train the model, execute the `train.py` script with the following command:

```bash
python scripts/train.py
```

### Command-Line Arguments
- `--config`: Path to the configuration file (default: `configs/default_config.yaml`)

Example:
```bash
python scripts/train.py --config configs/default_config.yaml
```

## Monitoring Training Progress
Training progress can be monitored through the logs generated by the script. Key metrics to track include:

- Training Loss
- Evaluation Loss
- Perplexity

## Saving and Loading Models
### Saving Models
The trained model parameters can be saved using the following logic (to be implemented in the `train.py` script):

```python
model.save_pretrained('/home/ubuntu/chat-agent/VishwamAI-main/saved_models')
```

### Loading Models
To load a saved model, use the following code:

```python
from transformers import AutoModel

model = AutoModel.from_pretrained('/home/ubuntu/chat-agent/VishwamAI-main/saved_models')
```

## Adding New Features
To integrate new features into the training process, follow these guidelines:

1. **Update the Tokenizer**:
   - Add new tokens or symbols to the tokenizer as needed.

2. **Modify the Model Architecture**:
   - Implement any necessary changes to the model architecture to support new features.

3. **Update the Training Script**:
   - Ensure the `train.py` script preprocesses input data correctly and integrates new features into the training loop.

4. **Test the Changes**:
   - Write and run tests to verify that the new features work as expected.

## Preprocessing Datasets
To preprocess the datasets for training, follow these steps:

1. **Mathematical Expressions**:
   - Ensure that the training and evaluation datasets include mathematical expressions where necessary.
   - Use the tokenizer to preprocess these expressions, ensuring they are tokenized correctly.

2. **Image to Text**:
   - Use Tesseract OCR to convert images to text and include these in the datasets.

3. **PDF to Text**:
   - Use PyMuPDF to extract text from PDF files and include these in the datasets.

4. **Audio to Text**:
   - Use SpeechRecognition to convert audio files to text and include these in the datasets.

5. **Video to Text**:
   - Use appropriate tools to extract text from video files and include these in the datasets.

## Conclusion
By following these steps, you can successfully train the VishwamAI chat agent model and integrate new features to enhance its capabilities. For any issues or further assistance, please refer to the project's troubleshooting guide or contact the project maintainer.
